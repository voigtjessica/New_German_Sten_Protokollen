{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0_01 : New try: slicing filtered texts manually\n",
    "\n",
    "1. Vou filtrar as sessoes em que se falam as nossas palavras chaves\n",
    "2. Depois eu vou apenas nesses arquivos e ajusto eles manualmente\n",
    "3. No fim eu volto e re-filtro, mandendo apenas os Tagesordnung que valem a pena ler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "['forst']\n",
      "5\n",
      "6\n",
      "7\n",
      "['waldschutz']\n",
      "8\n",
      "9\n",
      "['forstpolitische', 'forstlichen', 'waldbaulichen', 'forstwirtschaftlicher', 'forstwirtschaftliche']\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "['forstwirtschaftliche']\n",
      "19\n",
      "['waldreichen', 'forstwirtschaftlichen']\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "['holzt']\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "['holzschnittartig']\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "['holz']\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "['waldpolitische']\n",
      "67\n",
      "68\n",
      "['holzen']\n",
      "69\n",
      "70\n",
      "['forst']\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "['forstlichen', 'forstlichen', 'forstwirtschaftlichen']\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "['holzschnittartig']\n",
      "80\n",
      "81\n",
      "82\n",
      "['holzschnittartig']\n",
      "83\n",
      "84\n",
      "['holzschnittartigen']\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "['forstwirtschaftlichen']\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "['forstlicher', 'forstlicher']\n",
      "95\n",
      "['forstwirtschaftlichen', 'forstwirtschaftlichen', 'waldbrandgefahr256']\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "['forstlicher', 'forstwirtschaftlichen', 'forstlicher']\n",
      "101\n",
      "['wald']\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "['forstliche', 'forstlichem', 'forstlichen', 'forstliche', 'forstlichem', 'forstlichen', 'waldreichen', 'forstliche', 'forstlichem', 'forstlichen', 'waldreichsten', 'forstliche', 'forstlichem', 'forstlichen', 'forstliche', 'forstlichem', 'forstlichen']\n",
      "107\n",
      "['forstliche', 'forstlichem', 'forstlichen', 'forstwirtschaftlichen', 'forstwirtschaftlichen']\n",
      "108\n",
      "109\n",
      "['holzen']\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "['holzschnittartiger']\n",
      "115\n",
      "116\n",
      "['wald', 'waldeigentuemer', 'holzbe', 'wald', 'wald', 'wald', 'waldzustandserhebung', 'forstwirtschaftlichen', 'forstwirtschaftlichen', 'forstwirtschaftlichen']\n",
      "117\n",
      "118\n",
      "119\n",
      "['forstwirtschaftlichen', 'forstwirtschaftlichen']\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "['forstlichem', 'forstlichen', 'forstlichem', 'forstlichen', 'forstwirtschaftliche']\n",
      "125\n",
      "['forstlichem', 'waldverträgliches']\n",
      "126\n",
      "127\n",
      "['forstwirtschaftlichen', 'forstwirtschaftlichen', 'forstwirtschaftliches']\n",
      "128\n",
      "129\n",
      "['forstwirtschaftliche']\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "['forstlichen', 'forstlichen', 'waldpolitische']\n",
      "142\n",
      "143\n",
      "['holzschnittartig']\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "['holzen']\n",
      "152\n",
      "153\n",
      "154\n",
      "['forstliche', 'forstliche']\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "['forst', 'forstlicher', 'forst', 'forst', 'forst', 'forstlicher']\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "['forstlichen']\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "['wald']\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "['forstlichen', 'forstlichen', 'waldreichsten', 'forstlichen', 'forsten', 'forstwirtschaftlichen']\n",
      "194\n",
      "['walderhaltende']\n",
      "195\n",
      "['holzschnittartig']\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "['holzig']\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "['forstwirtschaftliche', 'forstwirtschaftliche', 'forstwirtschaftlich', 'forstwirtschaftlich']\n",
      "212\n",
      "213\n",
      "214\n",
      "['holzschnittartig']\n",
      "215\n",
      "['forstlichen']\n",
      "216\n",
      "['waldbraende', 'waldwirtschaftabkommen']\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "['holzbasierten']\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "['waldreichen']\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "['forstwirtschaftlicher', 'forstwirtschaftlichen']\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "['holzen', 'forst', 'waldes']\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2023-03-01_20_87.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2023-02-08_20_84.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2023-01-26_20_82.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2022-12-01_20_73.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2022-11-30_20_72.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2022-11-11_20_67.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2022-10-14_20_61.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2022-05-18_20_36.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2022-03-24_20_25.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2022-03-22_20_23.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2022-03-17_20_21.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2022-02-17_20_17.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2022-01-14_20_12.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-12-16_20_9.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-12-10_20_7.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-11-18_20_3.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-06-24_19_236.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-06-23_19_235.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-05-20_19_230.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-05-19_19_229.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-04-22_19_224.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-04-21_19_223.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-04-15_19_221.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-03-05_19_216.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-03-03_19_214.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-02-24_19_211.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-01-28_19_206.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-01-27_19_205.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2021-01-13_19_203.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2020-12-16_19_201.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2020-11-05_19_189.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2020-10-30_19_187.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2020-09-30_19_179.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2020-09-17_19_176.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2020-07-01_19_169.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2020-05-07_19_158.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2020-01-29_19_142.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2019-12-19_19_137.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2019-12-18_19_136.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2019-12-13_19_135.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2019-11-26_19_129.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2019-10-18_19_119.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2019-09-27_19_116.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2019-09-26_19_115.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2019-09-25_19_114.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2019-09-10_19_110.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2019-05-10_19_99.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2019-04-10_19_94.txt  saved to the file.\n",
      "C:\\Users\\JVoigt\\OneDrive - Universität für Weiterbildung Krems\\Dokumente\\Python Scripts\\New_German_Sten_Protokollen\\filtered_sections\\2019-02-13_19_79.txt  saved to the file.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "\n",
    "### Primeira parte: procurar quais sao as sessoes que têm algum dos termos:\n",
    "\n",
    "# #Abrindo DF com todas as sessoes\n",
    "general_df_original = pd.read_csv('0_general_df.csv', sep=';', encoding='UTF-8')\n",
    "\n",
    "general_df = general_df_original.drop('Unnamed: 0', axis=1)\n",
    "general_df = general_df.drop_duplicates()\n",
    "\n",
    "# Define the search terms and forbidden terms\n",
    "search_terms_holz = [r'\\bholz\\w*', r'\\bforst\\w*', r'\\bwald\\w*', r'\\bbioökonomie', r'\\bbioenergie', r'\\bmöbel\\w*']\n",
    "\n",
    "forbidden_terms = ['Holzner', 'Holzleitner', 'Waldneukirchen', 'Holzmann', 'Waldegg', 'Waldheims', 'Waldorf', 'Waldvier', 'Waldei',\n",
    "                   'Holzkreuze', 'Holzweg', 'Wald4tler', 'Walddorf', \n",
    "                  'Waldkirchen', 'Waldburg', 'Waldorfschule', 'Waldspaziergang', 'Holzfuß', 'Waldzell', 'Holzleit',\n",
    "                  'Waldbe', 'Waldneukirchen', 'Holzgau', 'waldorfmathematisch', 'Waldwürfe', 'Waldviertelbahn', 'Waldheim', 'Walding', 'Waldenstein', \n",
    "                  'Waldviertlerin', 'Holzlärm', 'Holzchild', 'Waldviertelautobahn', 'Holzinger', 'Waldviertler', 'Waldbrand', 'Waldbrände', 'Land- und forstwirtschaftliche Landeslehrpersonen-Dienstrechtsgesetz',\n",
    "                  'Land- und forstwirtschaftliche Landesvertrags­lehr­personengesetz']\n",
    "\n",
    "# Create the regular expression pattern with word boundaries\n",
    "padrao_holz = r\"\\b(\" + r\"|\".join(search_terms_holz) + r\")\\b\"\n",
    "regex_pattern = re.compile(padrao_holz)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "#### Aqui comeca o loop:\n",
    "for index, row in general_df.iterrows():\n",
    "    print(index)\n",
    "    text = row['text']\n",
    "\n",
    "    #fazendo a lista dos matches:\n",
    "    list_of_matches = re.findall(regex_pattern, text)\n",
    "\n",
    "    #para cada lista dos matches, verificar se a palavra está na lista dos forbiden terms\n",
    "    cleaned_matches = [x for x in list_of_matches if x not in forbidden_terms]\n",
    "    \n",
    "    \n",
    "    #se cleaned matches é > 0, manter a linha no df novo, senao, ir para a próxima:\n",
    "    if len(cleaned_matches) >= 1:\n",
    "\n",
    "        print(cleaned_matches)\n",
    "        termos = ', '.join(cleaned_matches)\n",
    "        \n",
    "\n",
    "        df_temp = pd.DataFrame([[termos]], columns=[\"terms_founded\"])\n",
    "        df_temp['id'] = row['id']\n",
    "        df_temp['dokumentart'] = row['dokumentart']\n",
    "        df_temp['typ'] = row['typ']\n",
    "        df_temp['vorgangsbezug_anzahl'] = row['vorgangsbezug_anzahl']\n",
    "        df_temp['dokumentnummer'] = row['dokumentnummer']\n",
    "        df_temp['wahlperiode'] = row['wahlperiode']\n",
    "        df_temp['herausgeber'] = row['herausgeber']\n",
    "        df_temp['pdf_hash'] = row['pdf_hash']\n",
    "        df_temp['datum'] = row['datum']\n",
    "        df_temp['titel'] = row['titel']\n",
    "        df_temp['fundstelle'] = row['fundstelle']\n",
    "        df_temp['vorgangsbezug'] = row['vorgangsbezug']\n",
    "        df_temp['aktualisiert'] = row['aktualisiert']\n",
    "        df_temp['text'] = row['text']\n",
    "\n",
    "        dfs.append(df_temp)\n",
    "\n",
    "    else:\n",
    "        next\n",
    "\n",
    "# Concatenate the list of DataFrames into a single DataFrame\n",
    "filtered_df = pd.concat(dfs)\n",
    "\n",
    "# remove duplicates:\n",
    "filtered_df = filtered_df.drop_duplicates(subset='pdf_hash')\n",
    "\n",
    "# Create a new column from 1 to n\n",
    "filtered_df['index'] = range(1, len(filtered_df) + 1)\n",
    "\n",
    "# Set the new column as the index\n",
    "filtered_df.set_index('index', inplace=True)\n",
    "\n",
    "# Assign empty string ('') to 'file_name' column\n",
    "filtered_df['section_file_name'] = ''\n",
    "\n",
    "#Now I'll save TXT files of the whole section, so I can divide the sections into Tagesordnungpunkt manually and later bring it back to the dataframe\n",
    "\n",
    "dir = \"C:\\\\Users\\\\JVoigt\\\\OneDrive - Universität für Weiterbildung Krems\\\\Dokumente\\\\Python Scripts\\\\New_German_Sten_Protokollen\\\\filtered_sections\\\\\"\n",
    "\n",
    "for index, row in filtered_df.iterrows():\n",
    "    text = row['text']\n",
    "    datum = row['datum']\n",
    "    dokumentnummer = row['dokumentnummer']\n",
    "    dokumentnummer = re.sub(\"/\", '_', dokumentnummer)\n",
    "\n",
    "    section_file_name = datum + '_' + dokumentnummer  + '.txt'      #Aqui o filename é apenas a data e o número da sessao\n",
    "    filtered_df.at[index, 'section_file_name'] = section_file_name\n",
    "    \n",
    "    section_file_name = dir + datum + '_' + dokumentnummer  + '.txt'      #Aqui é pra salvar\n",
    "    \n",
    "    # Open the file in write mode\n",
    "    # Salvando as sessoes\n",
    "    with open(section_file_name, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text)\n",
    "\n",
    "    \n",
    "    print(section_file_name , \" saved to the file.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquivos verificados\n",
    "\n",
    "Como eu nao conseguia automaticamente detectar o Tagesordnungspunkt, eu salvei os arquivos e verifiquei um a um onde comecava e terminada cada TOP\n",
    "\n",
    "```###TAGESORDNUNGSPUNKT###```\n",
    "\n",
    "Arquivos revisados:\n",
    "2019-02-13_19_79_\n",
    "2019-04-10_19_94_\n",
    "2019-05-10_19_99_\n",
    "2019-09-10_19_110_\n",
    "2019-09-25_19_114_\n",
    "2019-09-26_19_115_\n",
    "2019-09-27_19_116_\n",
    "2019-10-18_19_119_\n",
    "2019-11-26_19_129_\n",
    "2019-12-13_19_135_\n",
    "2019-12-18_19_136_\n",
    "2019-12-19_19_137_\n",
    "2020-01-29_19_142_\n",
    "2020-05-07_19_158_\n",
    "2020-07-01_19_169_\n",
    "2020-09-17_19_176_\n",
    "2020-09-30_19_179_\n",
    "2020-10-30_19_187_\n",
    "2020-11-05_19_189_\n",
    "2020-12-16_19_201_\n",
    "2021-01-13_19_203_\n",
    "2021-01-27_19_205_\n",
    "2021-01-28_19_206_\n",
    "2021-02-24_19_211_\n",
    "2021-03-05_19_216_\n",
    "2021-04-15_19_221_\n",
    "2021-04-21_19_223_\n",
    "2021-04-22_19_224_\n",
    "2021-05-19_19_229_\n",
    "2021-05-20_19_230_\n",
    "2021-06-23_19_235_\n",
    "2021-06-24_19_236_\n",
    "2021-11-18_20_3_\n",
    "2021-12-10_20_7_\n",
    "2021-12-16_20_9_\n",
    "2022-01-14_20_12_\n",
    "2022-02-17_20_17_\n",
    "2022-03-17_20_21_\n",
    "2022-03-22_20_23_\n",
    "2022-03-24_20_25_\n",
    "2022-05-18_20_36_\n",
    "2022-10-14_20_61_\n",
    "2022-11-11_20_67_\n",
    "2022-11-30_20_72_\n",
    "2022-12-01_20_73_\n",
    "2023-01-26_20_82_\n",
    "2023-02-08_20_84_\n",
    "2023-03-01_20_87_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda parte: dividindo o texto completo da sessao por Tagesordnungpunkt\n",
    "\n",
    "# Abrir cada um dos negócios \n",
    "# Adicionar no df como texto alternativo\n",
    "# Depois recortar no ###TAGESORDNUNGSPUNKT###\n",
    "\n",
    "dir = \"C:\\\\Users\\\\JVoigt\\\\OneDrive - Universität für Weiterbildung Krems\\\\Dokumente\\\\Python Scripts\\\\New_German_Sten_Protokollen\\\\filtered_sections_marked\\\\\"\n",
    "\n",
    "filtered_df['text_marked'] = ''\n",
    "\n",
    "#Aqui eu estou abrindo os textos marcados:\n",
    "for index, row in filtered_df.iterrows():\n",
    "    section_file_name = row['section_file_name']\n",
    "    section_file_name = dir + section_file_name \n",
    "\n",
    "    # Open the file in read mode\n",
    "    with open(section_file_name, 'r', encoding='utf-8') as file:\n",
    "        # Read the contents of the file\n",
    "        contents = file.read()\n",
    "\n",
    "    filtered_df.at[index, 'text_marked'] = contents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['waldschutz']\n",
      "['forstpolitische', 'forstlichen', 'waldbaulichen', 'forstwirtschaftlicher', 'forstwirtschaftliche']\n",
      "['forstwirtschaftliche']\n",
      "['waldreichen']\n",
      "['forstwirtschaftlichen']\n",
      "['holzt']\n",
      "['holzschnittartig']\n",
      "['holz']\n",
      "['waldpolitische']\n",
      "['holzen']\n",
      "['forst']\n",
      "['forstlichen', 'forstlichen', 'forstwirtschaftlichen']\n",
      "['holzschnittartig']\n",
      "['holzschnittartig']\n",
      "['holzschnittartigen']\n",
      "['forstwirtschaftlichen']\n",
      "['forstlicher']\n",
      "['forstwirtschaftlichen']\n",
      "['waldbrandgefahr256']\n",
      "['forstwirtschaftlichen']\n",
      "['forstlicher']\n",
      "['wald']\n",
      "['waldreichen']\n",
      "['forstliche', 'forstlichem', 'forstlichen', 'waldreichsten', 'forstliche', 'forstlichem', 'forstlichen']\n",
      "['forstliche', 'forstlichem', 'forstlichen']\n",
      "['forstwirtschaftlichen', 'forstwirtschaftlichen']\n",
      "['holzen']\n",
      "['holzschnittartiger']\n",
      "['wald', 'waldeigentuemer', 'holzbe', 'wald', 'wald', 'wald', 'waldzustandserhebung', 'forstwirtschaftlichen']\n",
      "['forstwirtschaftlichen', 'forstwirtschaftlichen']\n",
      "['forstwirtschaftlichen', 'forstwirtschaftlichen']\n",
      "['forstlichem', 'forstlichen']\n",
      "['forstwirtschaftliche']\n",
      "['forstlichem', 'waldverträgliches']\n",
      "['forstwirtschaftlichen', 'forstwirtschaftlichen', 'forstwirtschaftliches']\n",
      "['forstwirtschaftliche']\n",
      "['forstlichen', 'forstlichen', 'waldpolitische']\n",
      "['holzschnittartig']\n",
      "['forstliche']\n",
      "['forst']\n",
      "['forst', 'forst', 'forstlicher']\n",
      "['forstlichen']\n",
      "['wald']\n",
      "['forstlichen', 'forstlichen', 'waldreichsten', 'forstlichen', 'forsten']\n",
      "['forstwirtschaftlichen']\n",
      "['walderhaltende']\n",
      "['holzschnittartig']\n",
      "['holzig']\n",
      "['forstwirtschaftliche', 'forstwirtschaftliche', 'forstwirtschaftlich', 'forstwirtschaftlich']\n",
      "['holzschnittartig']\n",
      "['forstlichen']\n",
      "['waldbraende', 'waldwirtschaftabkommen']\n",
      "['holzbasierten']\n",
      "['waldreichen']\n",
      "['forstwirtschaftlicher', 'forstwirtschaftlichen']\n",
      "['holzen', 'forst', 'waldes']\n",
      "2023-02-08_20_84_1.txt  saved to the file.\n",
      "2023-01-26_20_82_2.txt  saved to the file.\n",
      "2022-12-01_20_73_3.txt  saved to the file.\n",
      "2022-11-30_20_72_4.txt  saved to the file.\n",
      "2022-11-30_20_72_5.txt  saved to the file.\n",
      "2022-11-11_20_67_6.txt  saved to the file.\n",
      "2022-10-14_20_61_7.txt  saved to the file.\n",
      "2022-05-18_20_36_8.txt  saved to the file.\n",
      "2022-03-24_20_25_9.txt  saved to the file.\n",
      "2022-03-22_20_23_10.txt  saved to the file.\n",
      "2022-03-17_20_21_11.txt  saved to the file.\n",
      "2022-02-17_20_17_12.txt  saved to the file.\n",
      "2022-01-14_20_12_13.txt  saved to the file.\n",
      "2021-12-16_20_9_14.txt  saved to the file.\n",
      "2021-12-10_20_7_15.txt  saved to the file.\n",
      "2021-11-18_20_3_16.txt  saved to the file.\n",
      "2021-06-24_19_236_17.txt  saved to the file.\n",
      "2021-06-23_19_235_18.txt  saved to the file.\n",
      "2021-06-23_19_235_19.txt  saved to the file.\n",
      "2021-05-20_19_230_20.txt  saved to the file.\n",
      "2021-05-20_19_230_21.txt  saved to the file.\n",
      "2021-05-19_19_229_22.txt  saved to the file.\n",
      "2021-04-22_19_224_23.txt  saved to the file.\n",
      "2021-04-22_19_224_24.txt  saved to the file.\n",
      "2021-04-22_19_224_25.txt  saved to the file.\n",
      "2021-04-21_19_223_26.txt  saved to the file.\n",
      "2021-04-15_19_221_27.txt  saved to the file.\n",
      "2021-03-05_19_216_28.txt  saved to the file.\n",
      "2021-03-03_19_214_29.txt  saved to the file.\n",
      "2021-03-03_19_214_30.txt  saved to the file.\n",
      "2021-02-24_19_211_31.txt  saved to the file.\n",
      "2021-01-28_19_206_32.txt  saved to the file.\n",
      "2021-01-28_19_206_33.txt  saved to the file.\n",
      "2021-01-27_19_205_34.txt  saved to the file.\n",
      "2021-01-13_19_203_35.txt  saved to the file.\n",
      "2020-12-16_19_201_36.txt  saved to the file.\n",
      "2020-11-05_19_189_37.txt  saved to the file.\n",
      "2020-10-30_19_187_38.txt  saved to the file.\n",
      "2020-09-17_19_176_39.txt  saved to the file.\n",
      "2020-07-01_19_169_40.txt  saved to the file.\n",
      "2020-07-01_19_169_41.txt  saved to the file.\n",
      "2020-05-07_19_158_42.txt  saved to the file.\n",
      "2020-01-29_19_142_43.txt  saved to the file.\n",
      "2019-12-19_19_137_44.txt  saved to the file.\n",
      "2019-12-19_19_137_45.txt  saved to the file.\n",
      "2019-12-18_19_136_46.txt  saved to the file.\n",
      "2019-12-13_19_135_47.txt  saved to the file.\n",
      "2019-11-26_19_129_48.txt  saved to the file.\n",
      "2019-10-18_19_119_49.txt  saved to the file.\n",
      "2019-09-27_19_116_50.txt  saved to the file.\n",
      "2019-09-26_19_115_51.txt  saved to the file.\n",
      "2019-09-25_19_114_52.txt  saved to the file.\n",
      "2019-09-10_19_110_53.txt  saved to the file.\n",
      "2019-05-10_19_99_54.txt  saved to the file.\n",
      "2019-04-10_19_94_55.txt  saved to the file.\n",
      "2019-02-13_19_79_56.txt  saved to the file.\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "\n",
    "# Aqui estou dividindo os 'text_marked' , que sao os textos que eu alterei:\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for index, row in filtered_df.iterrows():\n",
    "    text = row['text_marked']\n",
    "\n",
    "    # Dividing the text\n",
    "    tops = text.split('###TAGESORDNUNGSPUNKT###')\n",
    "    tops = tops[1:]\n",
    "\n",
    "    # Nessa parte do loop, eu vou verificar quais sao os TOP que contém os termos de madeira que a gente estabeleceu lá em cima:\n",
    "\n",
    "    for top in tops:\n",
    "        # Finding matches\n",
    "        list_of_matches = re.findall(regex_pattern, top)\n",
    "\n",
    "        # Checking forbidden terms\n",
    "        cleaned_matches = [x for x in list_of_matches if x not in forbidden_terms]\n",
    "\n",
    "        if len(cleaned_matches) >= 1:\n",
    "            print(cleaned_matches)\n",
    "            termos = ', '.join(cleaned_matches)\n",
    "\n",
    "            # Creating DataFrame\n",
    "            df = pd.DataFrame([top], columns=['tops'])\n",
    "            df['dokumentnummer'] = row['dokumentnummer']\n",
    "            df['wahlperiode'] = row['wahlperiode']\n",
    "            df['plenarprotokoll_id'] = row['id']\n",
    "            df['pdf_hash'] = row['pdf_hash']\n",
    "            df['datum'] = row['datum']\n",
    "            df['titel'] = row['titel']\n",
    "            df['wahlperiode'] = row['wahlperiode']\n",
    "            df['section_file_name'] = row['section_file_name']        # Filename ainda é data + sessao:\n",
    "\n",
    "            dfs.append(df)\n",
    "        else:\n",
    "            next\n",
    "\n",
    "# O tops_df é um dataframe que contém as informacoes da sessao e o texto APENAS do TOP:\n",
    "tops_df = pd.concat(dfs)\n",
    "\n",
    "#Deu certo!\n",
    "\n",
    "# Nessa terceira parte eu vou salvar os arquivos do TOP separadamente, pois assim eu consigo verificar a existência de algum padrao para dividir os reden:\n",
    "\n",
    "#Criando Ids\n",
    "tops_df['top_id'] = range(1, len(tops_df) + 1)\n",
    "# Criando uma coluna vazia para o nome dos file name do TOP\n",
    "tops_df['top_file_name'] = ''\n",
    "\n",
    "#Diretório onde eu vou salvar os TOPS\n",
    "dir = \"C:\\\\Users\\\\JVoigt\\\\OneDrive - Universität für Weiterbildung Krems\\\\Dokumente\\\\Python Scripts\\\\New_German_Sten_Protokollen\\\\filtered_tops\\\\\"\n",
    "\n",
    "tops_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for index, row in tops_df.iterrows():\n",
    "    text = row['tops']\n",
    "    datum = row['datum']\n",
    "    dokumentnummer = row['dokumentnummer']\n",
    "    dokumentnummer = re.sub(\"/\", '_', dokumentnummer)\n",
    "    top_id = row['top_id']\n",
    "    \n",
    "    top_file_name = datum + '_' + dokumentnummer + '_' + str(top_id) + '.txt'\n",
    "\n",
    "    tops_df.at[index, 'top_file_name'] = top_file_name\n",
    "    \n",
    "    print(top_file_name, \" saved to the file.\")\n",
    "\n",
    "    top_file_name = dir + top_file_name\n",
    "\n",
    "    # Open the file in write mode\n",
    "    with open(top_file_name, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### FOI AQUI QUE ALGO DEU ERRADO. FICARAM REGISTRADOS TODOS OS FILENAMNE COM O MESMO NOME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sao 56 documentos, mas ainda nao está bom porque sao muitas falas e certamente nao temos os termos em todas as falas. Entao eu vou fazer a mesma coisa para dividir as falas: Vou colocar o marcador ```###REDE###``` nas falas dos parlamentares, e depois re-dividir os TOP por rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sao duas divisoes: quando o presidente fala (nome do presidente:) e quando um parlamentar fala (nome do partido entre ():)\n",
    "\n",
    "#primeiro, eu preciso saber todos os nomes dos Vice-presidentes:\n",
    "diretorio = 'C:\\\\Users\\\\JVoigt\\\\OneDrive - Universität für Weiterbildung Krems\\\\Dokumente\\\\Python Scripts\\\\New_German_Sten_Protokollen\\\\filtered_tops\\\\*.txt'  \n",
    "\n",
    "arquivos_txt = glob.glob(diretorio)\n",
    "\n",
    "presidentes = []\n",
    "padrao = r\"(Vizepräsident \\w{3,}\\s\\w{3,})|(Vizepräsidentin \\w{3,}\\s\\w{3,})\"\n",
    "\n",
    "for arquivo in arquivos_txt:\n",
    "    with open(arquivo, 'r', encoding = \"utf-8\") as file:\n",
    "        conteudo = file.read()\n",
    "        \n",
    "        resultado = re.findall(padrao, conteudo)\n",
    "        presidentes = presidentes + resultado\n",
    "\n",
    "presidentes_sem_duplicatas = list(set(presidentes))\n",
    "\n",
    "# desnesting the list:\n",
    "presidentes = []\n",
    "\n",
    "for m in range(len(presidentes_sem_duplicatas)):\n",
    "   for n in range (len(presidentes_sem_duplicatas[m])):\n",
    "      presidentes.append(presidentes_sem_duplicatas[m][n])\n",
    "\n",
    "presidentes = list(filter(None, presidentes))\n",
    "\n",
    "# Agora eu vou adicionar ###REDE### antes da fala de cada uma das pessoas que vai falar:\n",
    "df_TOP_rede = []\n",
    "\n",
    "for arquivo in arquivos_txt:\n",
    "    with open(arquivo, 'r', encoding = \"utf-8\") as file:\n",
    "        conteudo = file.read()\n",
    "\n",
    "        # # #buscando os presidentes\n",
    "        for pres in presidentes:\n",
    "            if re.findall(pres, conteudo):\n",
    "                conteudo = re.sub(pres, \"###REDE###\" + pres, conteudo)\n",
    "\n",
    "        # # Buscando os speeches:\n",
    "        padrao = r\"\\w{2,}\\s\\w{2,}\\s\\(.*\\):\"\n",
    "        matches = re.findall(padrao, conteudo)\n",
    "\n",
    "        for match in matches:\n",
    "            match_escaped = re.escape(match) \n",
    "            conteudo = re.sub(match_escaped, \"###REDE###\" + match , conteudo)\n",
    "\n",
    "        df_temp = pd.DataFrame([[conteudo]], columns=['TOP'])\n",
    "        a = re.sub(r\"C:\\\\Users\\\\JVoigt\\\\OneDrive - Universität für Weiterbildung Krems\\\\Dokumente\\\\Python Scripts\\\\New_German_Sten_Protokollen\\\\filtered_tops\\\\\", \"\", arquivo)\n",
    "        a = re.sub(r\"\\.txt\", \"\", a)\n",
    "        df_temp['file'] = a\n",
    "\n",
    "        df_TOP_rede.append(df_temp)\n",
    "\n",
    "df_final = pd.concat(df_TOP_rede, ignore_index=True)\n",
    "\n",
    "# Eu vou usar o nome do file para fazer left join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['holzen']\n",
      "['forst', 'waldes']\n",
      "['forstwirtschaftlicher']\n",
      "['forstwirtschaftlichen']\n",
      "['waldreichen']\n",
      "['holzbasierten']\n",
      "['waldbraende', 'waldwirtschaftabkommen']\n",
      "['forstlichen']\n",
      "['holzschnittartig']\n",
      "['forstwirtschaftliche', 'forstwirtschaftliche', 'forstwirtschaftlich', 'forstwirtschaftlich']\n",
      "['holzig']\n",
      "['holzschnittartig']\n",
      "['walderhaltende']\n",
      "['forstlichen', 'forstlichen']\n",
      "['waldreichsten']\n",
      "['forstlichen']\n",
      "['forsten']\n",
      "['forstwirtschaftlichen']\n",
      "['wald']\n",
      "['forstlichen']\n",
      "['forst']\n",
      "['forst', 'forst']\n",
      "['forstlicher']\n",
      "['holzschnittartig']\n",
      "['forstlichen', 'forstlichen']\n",
      "['waldpolitische']\n",
      "['forstwirtschaftliche']\n",
      "['forstwirtschaftlichen', 'forstwirtschaftlichen']\n",
      "['forstwirtschaftliches']\n",
      "['forstlichem']\n",
      "['waldverträgliches']\n",
      "['forstwirtschaftliche']\n",
      "['forstwirtschaftlichen', 'forstwirtschaftlichen']\n",
      "['wald', 'waldeigentuemer', 'holzbe']\n",
      "['wald']\n",
      "['wald', 'wald', 'waldzustandserhebung']\n",
      "['forstwirtschaftlichen']\n",
      "['forstwirtschaftlichen', 'forstwirtschaftlichen']\n",
      "['holzschnittartiger']\n",
      "['holzen']\n",
      "['forstwirtschaftlichen', 'forstwirtschaftlichen']\n",
      "['waldreichen']\n",
      "['waldreichsten']\n",
      "['forstliche', 'forstlichem', 'forstlichen']\n",
      "['forstliche', 'forstlichem', 'forstlichen']\n",
      "['wald']\n",
      "['forstwirtschaftlichen']\n",
      "['waldbrandgefahr256']\n",
      "['forstwirtschaftlichen']\n",
      "['holzschnittartigen']\n",
      "['holzschnittartig']\n",
      "['holzschnittartig']\n",
      "['forstlichen', 'forstlichen']\n",
      "['forstwirtschaftlichen']\n",
      "['forst']\n",
      "['holzen']\n",
      "['waldpolitische']\n",
      "['holz']\n",
      "['holzschnittartig']\n",
      "['holzt']\n",
      "['waldreichen']\n",
      "['forstwirtschaftlichen']\n",
      "['forstwirtschaftliche']\n",
      "['forstpolitische', 'forstlichen']\n",
      "['waldbaulichen', 'forstwirtschaftlicher']\n",
      "['forstwirtschaftliche']\n",
      "['waldschutz']\n"
     ]
    }
   ],
   "source": [
    "# Agora é a hora de re-dividir os textos:\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for index, row in df_final.iterrows():\n",
    "    text = row['TOP']\n",
    "\n",
    "    # Dividing the text\n",
    "    reden = text.split('###REDE###')\n",
    "    reden = reden[1:]\n",
    "\n",
    "    for rede in reden:\n",
    "        # Finding matches com o que tem Holz:\n",
    "        list_of_matches = re.findall(regex_pattern, rede)\n",
    "\n",
    "        # Checking forbidden terms\n",
    "        cleaned_matches = [x for x in list_of_matches if x not in forbidden_terms]\n",
    "\n",
    "        if len(cleaned_matches) >= 1:\n",
    "            print(cleaned_matches)\n",
    "            termos = ', '.join(cleaned_matches)\n",
    "\n",
    "            # Creating DataFrame\n",
    "            df = pd.DataFrame([rede], columns=['reden'])\n",
    "            df['file_name'] = row['file']\n",
    "            df['terms'] = termos\n",
    "\n",
    "            dfs.append(df)\n",
    "        else:\n",
    "            next\n",
    "\n",
    "# Concatenate the list of DataFrames into a single DataFrame\n",
    "reden_df = pd.concat(dfs)\n",
    "\n",
    "#Deu certo!\n",
    "\n",
    "def get_parlamentar(r):\n",
    "    \"\"\"\"\n",
    "    Funcao que pega o nome do parlamentar a partir de um input de texto\n",
    "    \"\"\"\n",
    "    parlamentar = re.findall(r'^.*\\):', r )\n",
    "    if parlamentar:\n",
    "        parlamentar = re.sub(\":\", \"\", str(parlamentar[0]))\n",
    "    else:\n",
    "        for pres in presidentes:\n",
    "            if re.findall(pres, r ):\n",
    "                parlamentar = re.findall(pres, r)\n",
    "                parlamentar = re.sub(\":\", \"\", str(parlamentar[0]))\n",
    "    return parlamentar\n",
    "\n",
    "# Aplicando a função em cada elemento da coluna 'A' usando apply()\n",
    "reden_df['abgeordenete'] = reden_df['reden'].apply(lambda x: get_parlamentar(x))\n",
    "\n",
    "# Deu certo <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reden</th>\n",
       "      <th>file_name</th>\n",
       "      <th>terms</th>\n",
       "      <th>abgeordenete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter Stein (Rostock) (CDU/CSU):\\nHerr Präside...</td>\n",
       "      <td>2019-02-13_19_79_56</td>\n",
       "      <td>holzen</td>\n",
       "      <td>Peter Stein (Rostock) (CDU/CSU)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reden            file_name  \\\n",
       "0  Peter Stein (Rostock) (CDU/CSU):\\nHerr Präside...  2019-02-13_19_79_56   \n",
       "\n",
       "    terms                     abgeordenete  \n",
       "0  holzen  Peter Stein (Rostock) (CDU/CSU)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reden_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalmente, chegou a hora de juntar as informacoes sobre a sessao parlamentar aos redes:\n",
    "\n",
    "infos_df = tops_df\n",
    "infos_df = infos_df.drop('tops', axis = 1)   # derrubando o texto do tops, pq eu nao preciso dele\n",
    "infos_df = infos_df.rename(columns={'top_file_name': 'file_name'})\n",
    "\n",
    "# define function to remove '.txt' extension from file names\n",
    "def remove_txt_extension(file_name):\n",
    "    return re.sub('\\.txt', '', file_name)\n",
    "\n",
    "# apply function to 'file_name' column\n",
    "infos_df['file_name'] = infos_df['file_name'].apply(remove_txt_extension)\n",
    "\n",
    "reden_df_final = pd.merge(reden_df, infos_df, how='left', on='file_name')\n",
    "\n",
    "reden_df_final = reden_df_final.drop_duplicates()\n",
    "\n",
    "reden_df_final['reden_id'] = range(1 , len(reden_df_final) + 1)\n",
    "\n",
    "reden_df_final['reden_file_name'] = reden_df_final['abgeordenete'] + reden_df_final['file_name'] + '_' + reden_df_final['reden_id'].astype(str) + '.txt'\n",
    "\n",
    "\n",
    "def fix_names(x):\n",
    "    x = re.sub('\\(' , '', x)\n",
    "    x = re.sub('\\)' , '', x)\n",
    "    x = re.sub('\\/' , '_', x)\n",
    "    x = re.sub('\\s' , '_', x)\n",
    "    return x\n",
    "\n",
    "reden_df_final['reden_file_name'] = reden_df_final['reden_file_name'].apply(lambda x: fix_names(x))\n",
    "\n",
    "reden_df_final.head()\n",
    "# Agora vou finalmente exportar isso!\n",
    "\n",
    "#Diretório onde eu vou salvar os TOPS\n",
    "dir = \"C:\\\\Users\\\\JVoigt\\\\OneDrive - Universität für Weiterbildung Krems\\\\Dokumente\\\\Python Scripts\\\\New_German_Sten_Protokollen\\\\filtered_reden\\\\\"\n",
    "\n",
    "for index, row in reden_df_final.iterrows():\n",
    "    text = row['reden']\n",
    "    file_name =  dir + row['reden_file_name']\n",
    "    \n",
    "    # Open the file in write mode\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "reden_df_final.to_csv('reden_df_final.csv', encoding='utf-8', sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
